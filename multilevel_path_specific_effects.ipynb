{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLS_X = ['AP','P','AI','I']\n",
    "COLS_Y = ['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_logit(x):\n",
    "    z = 1./(1+np.exp(-x))\n",
    "    s = np.random.binomial(n=1, p=z)\n",
    "    return s\n",
    "    \n",
    "\n",
    "def gen_synth_data(N=10000, verbose=False):\n",
    "    np.random.seed(10)\n",
    "    '''Example 4 from main text\n",
    "    Variables\n",
    "    A_P: Neighborhood_SES as low or high 0 or 1\n",
    "    A_I: Individual_SES as low or high 0 or 1\n",
    "    P: population_level attributes \n",
    "    I: individual_level attributes\n",
    "    Y: health status 0 or 1'''\n",
    "    \n",
    "    # Regression coefficients\n",
    "    # gamma_PAP = 1\n",
    "    # gamma_AIAP = 3\n",
    "    # gamma_AIP = 2\n",
    "    # gamma_IAP = 8\n",
    "    # gamma_IAI = 10\n",
    "    # gamma_YP = 1\n",
    "    # gamma_YI = 1\n",
    "    # gamma_YAI = 2\n",
    "    #zero ap effect\n",
    "    gamma_PAP = 1\n",
    "    gamma_AIAP = 3\n",
    "    gamma_AIP = 2\n",
    "    gamma_IAP = 8\n",
    "    gamma_IAI = 10\n",
    "    gamma_YP = 1\n",
    "    gamma_YI = 1\n",
    "    gamma_YAI = 2\n",
    "    scale_e = 0.64\n",
    "    \n",
    "    AP = random_logit(np.random.uniform(0,1, size=N))\n",
    "    P  = gamma_PAP*AP + 0.001*np.random.normal(loc=0.0, scale=scale_e , size=N)\n",
    "    AI = random_logit(gamma_AIAP*AP + gamma_AIP*P + 0.001*np.random.normal(loc=0.0, scale=0.1, size=N))\n",
    "    I  = gamma_IAP*AP + gamma_IAI*AI + 0.001*np.random.normal(loc=0.0, scale=scale_e, size=N)\n",
    "    # Y  = random_logit(gamma_YP*P + gamma_YI*I + gamma_YAI*AI+ 0.001*np.random.normal(loc=0.0, scale=scale_e, size=N))\n",
    "    Y  = gamma_YP*P + gamma_YI*I + gamma_YAI*AI+ 0.001*np.random.normal(loc=0.0, scale=scale_e, size=N)\n",
    "    data_Y = Y\n",
    "    data_X = np.stack([AP,P,AI,I],axis=1)\n",
    "    cols_X = ['AP','P','AI','I']\n",
    "    cols_Y = ['Y']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data_X, data_Y, test_size=0.25, random_state=42)\n",
    "    X_train = pd.DataFrame(data = X_train, columns = cols_X)\n",
    "    X_test  = pd.DataFrame(data = X_test, columns = cols_X)\n",
    "    Y_train = pd.DataFrame(data = Y_train, columns = cols_Y)\n",
    "    Y_test  = pd.DataFrame(data = Y_test, columns = cols_Y)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = gen_synth_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_models(X_train, Y_train, formula_P, formula_AI, formula_I, formula_Y):\n",
    "    data = pd.concat([X_train,Y_train],axis=1)\n",
    "    # print(data.head())\n",
    "    \n",
    "    # cols_X = ['AP','P','AI','I']\n",
    "    # cols_Y = ['Y']\n",
    "    # #P ~ AP\n",
    "    model_P = LinearRegression(fit_intercept=True)\n",
    "    model_P.fit(data[['AP']],data[['P']])\n",
    "    beta_P = model_P.coef_\n",
    "   \n",
    "\n",
    "    # # AI ~ P+AP\n",
    "    model_AI = LogisticRegression(penalty='l2',solver='saga', fit_intercept=True)\n",
    "    model_AI.fit(data[['P','AP']],data[['AI']])\n",
    "    beta_AI = model_AI.coef_\n",
    "   \n",
    "    # # I ~ AP + AI\n",
    "    model_I = LinearRegression(fit_intercept=True)\n",
    "    model_I.fit(data[['AP','AI']],data[['I']])\n",
    "    beta_I = model_I.coef_\n",
    "  \n",
    "\n",
    "    # # Y ~ P + I + AI\n",
    "    # model_Y = LogisticRegression(penalty='l2',solver='saga', fit_intercept=True)\n",
    "    model_Y = LinearRegression(fit_intercept=True)\n",
    "\n",
    "    model_y = model_Y.fit(data[['P','I','AI']],data[['Y']])\n",
    "    beta_Y = model_Y.coef_\n",
    "    \n",
    "    return model_Y,{'P':beta_P, 'AI':beta_AI, 'I':beta_I, 'Y':beta_Y}\n",
    "\n",
    "\n",
    "def classifiers_all(X_train,Y_train,cols_X=COLS_X,cols_Y=COLS_Y):\n",
    "    #formulas for the different classifiers:\n",
    "    #P vs AP\n",
    "    formula_P = 'P ~ AP'\n",
    "\n",
    "    #AI vs AP,P\n",
    "    formula_AI = 'AI ~ AP + P'\n",
    "\n",
    "    #I vs AP,AI\n",
    "    formula_I = 'I ~ AP + AI'\n",
    "\n",
    "    #Y vs P,I,AI\n",
    "    formula_Y = 'Y ~ P + I + AI'\n",
    "\n",
    "    model_Y, beta_lm = fit_models(X_train,Y_train, formula_P, formula_AI, formula_I, formula_Y)\n",
    "\n",
    "    return model_Y,beta_lm\n",
    "model_Y,beta_lm = classifiers_all(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate path-specific effects\n",
    "def pse(beta_lm):\n",
    "    theta_y = beta_lm['Y'][0]\n",
    "    theta_i = beta_lm['I'][0]\n",
    "    theta_ai = beta_lm['AI'][0]\n",
    "    theta_p = beta_lm['P'][0]\n",
    "\n",
    "    pse_ai = {'ai_y': theta_y[2],\\\n",
    "              'ai_i_y':theta_y[1]*theta_i[1] ,\\\n",
    "              'ai__y': theta_y[2]+theta_y[1]*theta_i[1] }\n",
    "\n",
    "    pse_ap_ai = {'ap_p_y,ai_y': theta_y[0]*theta_p[0]+theta_y[2],\\\n",
    "                'ap_p_y,ai_i_y': theta_y[0]*theta_p[0]+theta_y[1]*theta_i[1],\\\n",
    "                'ap_p_y,ai_i_y,ai_y': theta_y[0]*theta_p[0]+theta_y[1]*theta_i[1]+theta_y[2],\\\n",
    "                'ap_i_y,ai_i_y': theta_y[1] *(theta_i[1] + theta_i[0]),\\\n",
    "                'ap_i_y,ai_y':theta_y[2] + theta_y[1]*theta_i[0],\\\n",
    "                'ap_i_y,ai__y':theta_y[2] + theta_y[1] *(theta_i[1] + theta_i[0]),\\\n",
    "                'ap__y,ai__y':theta_y[2] + theta_y[1] *(theta_i[1] + theta_i[0])+theta_y[1]*theta_i[0]}\n",
    "    return pse_ai,pse_ap_ai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai_y': 2.034593479286903, 'ai_i_y': 9.965387176764633, 'ai__y': 11.999980656051536}\n",
      "{'ap_p_y,ai_y': 3.0622841688726945, 'ap_p_y,ai_i_y': 10.993077866350424, 'ap_p_y,ai_i_y,ai_y': 13.027671345637327, 'ap_i_y,ai_i_y': 17.937681587713826, 'ap_i_y,ai_y': 10.006887890236094, 'ap_i_y,ai__y': 19.97227506700073, 'ap__y,ai__y': 27.94456947794992}\n"
     ]
    }
   ],
   "source": [
    "pse_ai,pse_ai_ap = pse(beta_lm)\n",
    "print(pse_ai)\n",
    "print(pse_ai_ap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
